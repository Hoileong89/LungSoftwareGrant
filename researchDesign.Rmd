## __3(c) Research design__

### 3(c.1) Preliminary data

### 3(c.1.1) ANTs and the neuroimaging community

Deficiency of publicly available tools within the neuroscience community has been one of
the primary motivations for the inception and continued development of our Advanced
Normalization Tools (ANTs).  Our team is well-recognized for seminal contributions to the
field of image registration that date back to the original elastic matching method of Bajcsy
and co-investigators [@Bajcsy:1982aa;@Bajcsy:1989aa;@Gee:1993aa]. Our most recent work,
embodied in the ANTs open-source, cross-platform toolkit for multiple modality image processing
(http://picsl.upenn.edu/ software/ants/), continues to set the standard in the field. ANTs not
only encodes the most advanced results in registration research, notably the Symmetric Normalization
(SyN) algorithm for diffeomorphisms [@Avants:2011ab], but also packages these within a full
featured platform that includes an extensive library of similarity measures, transformation types, and
regularizers. Indeed, it serves
as the basis for the registration component of the latest version of the National Library of
Medicine Insight Toolkit (ITK) programming library (http://www.itk.org). The
combination of state-of-the-art algorithms and feature-rich flexibility has translated
to top-placed rankings in major independent evaluations for certain elements of the ANTs
toolkit:

* SyN was a top performer in a fairly recent large-scale brain normalization evaluation [@Klein:2009aa].
* SyN also competed in the Evaluation of Methods for Pulmonary Image
REgistration 2010 (EMPIRE10) challenge [@Murphy:2011aa] where it was the top performer
for the benchmarks
used to assess lung registration accuracy and biological plausibility of the inferred
transform (i.e., boundary alignment, fissure alignment, landmark correspondence, and
displacement field topology).
* The joint label fusion algorithm of [@Wang:2012aa;@Wang:2013aa] (coupled with SyN)
  performed well in the MICCAI 2012 challenge for labeled brain data [@Landman2012]
  and in 2013 for labeled canine hind leg data [@Asman2013].
* The multivariate template capabilities in ANTs were combined with random forests to win
the Brain Tumor segmentation (BRATS) competition at MICCAI 2013 [@Tustison:2014aa].
* A B-spline variant of the SyN algorithm [@Tustison:2013ac] won the best paper award at the
STACOM 2014 workshop for cardiac motion estimation [@Tustison:2015ab].








ANTs takes advantage of
the mature Insight ToolKit in providing an optimal software framework for building scripts
and programs specifically for neuroimaging.  For example, the following core neuroimage
processing algorithms have been made available through our ANTs toolkit (complete with
online self-contained examples with developer-tuned parameters) and have been used extensively by our group and
others:

* brain normalization [@Avants:2011ab;@Avants:2014aa] (https://github.com/stnava/BasicBrainMapping),
* brain template generation [@Avants:2010aa] (https://github.com/ntustison/TemplateBuildingExample),
* skull-stripping or brain extraction [@Avants:2010ab;@Tustison:2014ab] (https://github.com/ntustison/antsBrainExtractionExample),
* prior-based brain tissue segmentation [@Avants:2011ab] (https://github.com/ntustison/antsAtroposN4Example),
* cortical  thickness estimation [@Das:2009aa;@Tustison:2014ab] (https://github.com/ntustison/antsCorticalThicknessExample),
* brain tumor segmentation [@Tustison:2014aa] (https://github.com/ntustison/ANTsAndArboles), and
* cortical labeling [@Wang:2012aa;@Wang:2013aa] (https://github.com/ntustison/MalfLabelingExample).


### 3(c.1.2) The significance of ANTs for the pulmonary imaging community

Analogously, several algorithmic categories exist for lung image analysis which, as we have
stated previously, do not exist in any comprehensive, publicly available package.  An
extensive survey concentrating on the years 1999–2004 is given in [@Sluimer:2006aa] which covers computer
aided diagnosis of lung disease and lung cancer in CT (i.e., detection and tracking of
pulmonary nodules) and provides an overview of the many relevant segmentation methods for
pulmonary structures. Although many algorithms existed at the time, continued technical
development has only increased the number of available algorithms.  The following is a small
sampling of more recently reported techniques for CT analysis:

* whole lung differentiation from the chest wall (e.g., [@De-Nunzio:2011aa;@Prasad:2008aa;@Wang:2009aa;@Rikxoort:2009aa])
* bronchial structure extraction (e.g., [@Zheng:2007aa;@Nakamura:2008aa] and the many submissions to the recent Extraction of Airways from CT (ExACT) challenge of the 2nd International Workshop on Pulmonary Image Analysis [@Lo:2009aa]),
* vasculature segmentation (e.g., [@Agam:2005aa;@Korfiatis:2011aa]),
* lobe and/or fissure detection (e.g., [@Qi:2014aa;@Doel:2015aa]),
* feature extraction and classification (e.g., [@Uppaluri:1999aa;@Rosas:2011aa;@DeBoer:2014aa]), and
* nodule detection (e.g., [@Messay:2010aa;] and the many submissions to the Automatic Nodule Detection (ANODE09) challenge of the 2009 CAD Conference of SPIE Medical Imaging [@Ginneken:2010aa]).

Since this list is restricted to CT image analysis, inclusion of additional techniques
specific to other modalities will have additional benefit.  For example, ventilation-based
segmentation for analysis of ventilation lung imaging (e.g., [@Tustison:2011aa] which was
implemented within the ANTs framework) will also have significant impact in a comprehensive
lung image analysis suite.  Since most of the tools that have been developed within the
ANTs framework have generic applicability, crucial to the development of our proposed toolset
will be domain-specific experience.  For example, although ANTs performance in brain
registration has been independently evaluated and found to be of relatively high quality
[Klein2009], tailoring our registration tool in the EMPIRE10 challenge (Evaluation of Methods
for Pulmonary Image REgistration 2010) required significant empirically-based tuning.  In
addition, new innovations in diffeomorphic registration technology has led to a Symmetric
Normalization B-spline variant which has demonstrated accurate normalizations [@Tustison:2013ac],
and transformations which are particularly well-suited for pulmonary data [@Tustison:2015aa].

<!--
Our previous experience in providing well-vetted tools for neuroimage analysis and our extensive
pulmonary research background makes our group well-suited for accomplishing the aims of this proposal and much
of it has and will use ITK and ANTs as a software foundation.
-->













### 3(c.2) Specific Aim 1:   To develop a set of open-source software tools for CT, proton, and 3He pulmonary computational analysis.

Although the proposed software library would be extendable based on new methodological
developments and continued analysis experience, the core development will include several fundamental
tools:

__B-spline-based Symmetric Normalization.__  A thorough comparison with the
well-known ANTs SyN algorithm [@Avants:2008aa] was performed with a B-spline variant [@Tustison:2013ac].
This evaluation utilized multiple publicly available, annotated brain data sets and
demonstrated statistically significant improvement in label overlap measures.  As part of
that study, we produced the scripts ``antsRegistrationSyN.sh`` and
``antsRegistrationSyNQuick.sh`` which provide a simple interface to our normalization tools
for brain-specific normalization based on our extensive experience.

Similarly, we used the EMPIRE10 challenge framework to provide an additional comparison in
the context of pulmonary CT image registration [@Tustison:2012aa].  Registration accuracy
is based on a combination of factors including lung boundary and fissure overlap, landmark
correspondence, and topology considerations in the displacement field.  In this domain, the
B-spline variant showed a separate performance gain and has since become
the preferred transformation model for small deformation image registration problems
(an additional domain is cardiac MRI where it recently won the best paper
award [@Tustison:2015ab]).  As part of the development, we will provide simple script-based
interfaces for lung-specific normalization tasks.

__Multi-feature CT and multi-modal MRI template generation.__  Given the variability in lung shape across
populations and the lack of publicly available lung atlases, generating population- or
subject-specific templates significantly enhances study potential.  Although the template
construction algorithm described in [@Avants:2010aa] was applied to T1-weighted brain data
(with the extension of multimodal data described in [@Tustison:2014aa]), it is sufficiently
generic  such that it is easily applied to pulmonary data.

For example, in Fig. 4, we illustrate the major processing components of a recent study
analyzing local changes based on a pulmonary treatment plan [@Tustison:2013ad].  This
study employed several of the tools we are proposing for inclusion in the specified aims.
The firs major component is the construction of a single-subject 3He/proton MRI
template for all five imaging time points.  This step generates the statistical coordinate
system for the voxelwise regression analysis of the normalized intensities to determine
correlation with expected treatment effects.

![Voxelwise regression analysis to determine image-based response to treatment.  First,
a multi-modal, single-subject template is created to bring all time point images to
the same coordinate system.  4-D segmentation is performed on the longitudinal time series
of 3-D image volumes.  Treatment
effects are expected to follow the simplified treatment hypothesis illustrated with the
dashed blue line in the plot on the right.  To explore how the longitudinal change in expected
ventilation follows this treatment hypothesis with image data, we smooth the aligned expected
ventilation maps (to account for potential voxelwise misalignments) and then quantify how the
voxelwise intensities regress with the simplified treatment hypothesis.  This quantification
is visualized using the correlation maps depicted in the template space (top right).  Positive
correlations with the expected treatment effect are rendered in orange whereas negative correlations
are rendered in blue.](Figs/longitudinalStudy.png)

__Atlas-based lung segmentation.__  Identification of anatomical structure in MRI is often a
crucial preprocessing step for quantification of morphological features or ventilation
information from functional images.  Quantitative regional analysis often requires the
identification of lung and lobar anatomy.  Although much algorithmic research for lung
segmentation has been
reported in the CT literature [@Rikxoort:2013aa], co-opting such technologies is complicated by
MRI-specific issues such as RF coil inhomogeneity, presence and resolution of structural detail, and
the absence of a physically-based intensity scaling.

We recently proposed a multi-atlas approach for automatically segmenting the left and right
lungs in proton MRI [@Tustison:2015aa].  Multi-atlas approaches to segmentation have proven highly
successful in neuroimaging [@Wang:2012aa;@Wang:2013aa] and these methods translate readily to
the pulmonary domain.  Wherease many current strategies for lung image segmentation employ
low-level processing techniques based on encodable heuristics, consensus-based strategies,
in contrast, optimize the prior knowledge applied to a specific segmentation problem (cf Figure 3).
The evaluation of our proposed method [@Tustison:2015aa] demonstrated good performance
with Jaccard overlap measures for the left and right lungs being $0.966 \pm 0.018$ and
$0.970 \pm 0.016$, respectively.  One of the benefits of this approach is that can also
be applied effectively to pulmonary CT.

![Sample lung and lobe estimation results in both proton MRI and CT using our
atlas-based strategy.  (Left) Lung segmentation and lobe estimation results for the given
proton MRI.  Although lobe estimation is dependent solely on the warped atlases, we are
able to obtain accurate estimates of lobes which are useful for more regional analysis
and provide a more intuitive and universal subdivision of the lungs than previous partitioning
schemes.  (Right) The utility of this method extends to CT where the integrity of lobar anatomical
markers (such as the lack of fissures illustrated by the red arrows) have been compromised due to
disease.](Figs/lungEstimation.png)

__Atlas-based lobe estimation.__  For regional investigation of certain lung pathologies and
conditions, it is often useful to quantify measurements of interest within more localized
regions, such as the lobes.  However there is little (if any) usable information in proton
MRI for image-based lobar segmentation which has led to alternative geometric subdivisions
which are ad hoc, non-anatomical, and do not adequately address intra- and inter-subject
correspondences.  However, we can take advantage of
inter-subject similarities in lobar geometry to provide a prior-based estimation of
lobar divisions using a consensus labeling approach (cf Figure 2).

To generate the lobe segmentation in a target proton or CT lung image, we first generate the
binary whole lung mask using the whole lung atlas-based estimation.  We
then register the set of CT lung masks which have beeen expertly annotated to the target
binary lung mask using the B-spline
SyN registration approach described earlier [@Tustison:2013ac].
 Subsequently, we warp the set of CT lobe labels to the target image using
the CT mask-to-target mask transformation.  Since we have no intensity information inside
the target lung mask and CT atlas lung masks, we use a simply majority voting strategy to
generate the optimal labeling for the target image.  Following the majority voting, we
remove any labelings outside the lung mask and assign any unlabeled voxels with the label
closest in distance to that voxel.  This methodology is more thoroughly described in
[@Tustison:2015aa] where we showed that lobar overlap measures in proton MRI were on par
with the  state-of-the-art CT methods where fissure information is actually visible
(left upper: $0.882 \pm 0.059$, left lower: $0.868 \pm 0.06$, right upper: $0.852 \pm 0.067$,
right middle: $0.657 \pm 0.130$, right lower: $0.873 \pm 0.063$).

__Ventilation quantification.__
Automated or semiautomated approaches for classifying areas of varying degrees of ventilation
are of potential benefit for pulmonary functional analysis.  In [@Tustison:2011aa], we presented
an automated algorithmic pipeline for ventilation-based partitioning of the lungs in hyperpolarized
3He and 129Xe MRI.  Without ground truth data for evaluation, we used a consensus labeling approach [@Warfield:2004aa]
to simultaneously estimate the true segmentation from given ``raters''
which included the segmentation from our automated approach and the manual tracings of three trained
individuals.  In terms of combined specificity and sensitivity, our automated algorithm
demonstrated superior performance with the added benefit of being reproducible and less
time-consuming.

Since the initial development, we have continued to improve this segmentation pipeline by
incorporating an iterative bias-correction/segmetnation estimation scheme.   An additional
component that improves results is an ANTs-based implementation of the patch-based denoising protocol
described in [@Manjon:2010aa].  Example longitudinal segmentation results are provided
in Figure 4.

![Pulmonary functional segmentation using the algorithmic framework first described in [@Tustison:2011aa]
for hyperpolarized 3He MRI.  These data were taken from a current study looking at the
implications in ventilation pre- and post-albuterol intake including an additional
acquisition at some delay period following the post-albuterol imaging.  The
ventilation-based segmentation is as follows:  red = no ventilation, green = poorly
ventilated, blue = normally ventilated, and yellow = well-ventilated.
Note the improvement in both the qualitative assessment of the ventilation map (top) and the corresponding
segmentation time course (bottom) followed by an approximate return to pre-albuterol
conditions following the delay period.](Figs/prePostAlbuterol.png)

__Quantitative CT indices.__  Imaging biomarkers for characterizing emphysema in CT have
have been well researched, although there are ample opportunities to refine these methods
as well as to introduce more advanced approaches.  Examples of the latter include texture
analysis for identifying the centrilobular and groundglass opacities and fractal and
connectivity approaches to differentiate centrilobular from panlobular emphysema. The
indices for CT image analysis can roughly be divided into those that characterize the
pulmonary parenchyma:
  volumetric tissue (e.g., [@Coxson:1999aa;@Perez:2005aa]),
   distribution of low attenuation areas (LAA) (e.g., [@Coxson:2005aa;@Stolk:2007aa]),
   cooccurrence and run-length matrix features (e.g., [@Uppaluri:1999aa;@Xu:2006aa]),
   attenuation statistics (e.g., [@Gevenois:1996aa;@Hoffman:2006aa]),
   deformation measures (e.g., [@Gee:2003aa;@Sundaram:2005aa]), and
   stochastic fractal dimension features (e.g., [@Uppaluri:1999aa;@Hoffman:2006aa])
and those that characterize the airways (e.g., [@Aykac:2003aa;@Park:1998aa;@Ederle:2003aa]).

The former are important
for subjects with an emphysematous component of disease, whereas the latter are important
for subjects with a bronchitic component of disease. An important premise of this
proposal is that many of these measurements can also be directly applied to discriminative
analysis using 3He MRI for a variety of lung diseases.
These indices can also be studied not
only at any particular single time point, but also for changes with time. The addition of
quantitative morphologic measurements of the airways provides an assessment of the
contribution of airway changes to chronic lung disease.

\input{ct_table.tex}

Table 1 provides an overview of these types of
discriminative measurements that can be used for CT and 3He lung assessment.
We have already
implemented many of these image features and have contributed the result of our work to
the Insight Toolkit (ITK) of the National Institutes of Health (e.g., [@Tustison:2008aa;@Tustison:2009aa]). As an
open-source repository for medical image analysis algorithms, contribution of our work
to the ITK allows researchers full access to the latest image analysis algorithms in
addition to avoiding research redundancy. It is also beneficial in that the entire ITK
community participates in the vetting of the software library.

__Airway and vessel segmentation.__  In describing the quantitative CT lung indices,
it was pointed out that lung airway morphology has been previously utilized as a biomarker
for disease characterization.  Additionally, there are other potential uses motivating
the inclusion of airway segmentation in any pulmonary image analysis toolkit (cf Figure 5).
In an evaluation of 15 airway segmentation algorithms [@Lo:2012aa]
it was shown that no algorithm was capable of ``extracting more than 77% of the reference.''
Our plan is to initially provide an implementation of the algorithm developed by our group [@Song:2010aa].
Instead of mixing airway segmentation and leakage detection at every iteration, this work divides
this problem into a hypothesis generation of thin airway paths and a post processing
procedure of removing leakage path candidates. For the purpose of generating as many
hypotheses as possible, a novel speed function for thin airways is used. To exclude
leakage regions, a novel cost function defined on the whole path candidate is used.
Such a scheme is more flexible when evaluating the whole path and can be viewed as
complementary to current region growing methods.

![Potential clinical use case for identifying the feeding airway branch path to the
ventilation defect.  The functional ventilation image is normalized to the corresponding
CT image.  The airways are segmented in the individual subject space.  After identification
of the ventilation defect of interest, we can automatically determine the bronchiole
pathway from the trachea to the defect.](Figs/airways.png)


__Specific Aim 2.__  To provide multiple sets of multi-modal annotated lung data (CT, proton, and He3) for public use.

__Specific Aim 3.__ Evaluate and disseminate multiple complete studies with input data from
multiple investigators to showcase the utility of the tools and data provided with this proposal.

### Anticipated difficulties
Signal intensity in the lungs is poor in areas of low ventilation. COPD and asthma are
obstructive lung diseases which exhibit focal areas of decreased signal intensity on 3HeMRI
which are thought to correspond to areas of reduced ventilation. These ventilation defects
severely inhibit our ability to detect the lung boundaries for proper segmentation. Also,
most of the COPD and asthmatic patients will have ventilation defects with the moderate
asthmatics having greater than 1 defect per slice also negatively affecting boundary
delineation. Note that there are similar issues for CT images of severe pathologies.
However, given the shape and intensity prior statistics contained by our 3HeMRI and CT
lung templates, it is expected that the templates, in combination with our proposed
segmentation algorithms, will be sufficient to provide a good initialization for subsequent
manual segmentation if they do not yield an adequate segmentation result. The CT data,
which provides excellent contrast between the lung and chest wall, can also be used to
inform the 3HeMRI segmentation.






\clearpage

\newpage

# References

