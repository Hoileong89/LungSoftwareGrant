
# Research Strategy

## __3(a) Significance__
### 3(a.1) The importance of publicly available software tools for domain-specific medical image analysis
Well-vetted and publicly available software is a significant benefit
to targeted research communities.  For example, the neuroscience community has greatly
benefited from highly evolved software packages such as FreeSurfer [@Fischl:2012aa], the FMRIB Software
Library (FSL) [@Jenkinson:2012aa], the Analysis of Functional NeuroImages (AFNI) package [@Cox:2012aa], and the
Statistical Parametric Mapping (SPM) package [@Ashburner:2012aa].  Performing a pubmed query for any one of
these softwares every year for the past decade (cf Figure 1) illustrates the growing use of
such packages and the research studies that are produced as a result.  However, despite the
absolute number of articles produced using such software and the year-by-year usage increase,
no such analogous set of tools exist for pulmonary-specific research.  In fact, in a recent
review of CT- and MRI-derived biomarkers for pulmonary clinical investigation, the authorial
consensus is that ``universally available image analysis software'' is a major hinderance
to more widespread usage of such imaging biomarkers [@Hoffman:2015aa].

```{r pubmedQuery, include=TRUE, echo=FALSE, warning=FALSE, message=FALSE, results="hide", fig.height=3, fig.width=6, fig.cap="Number of articles per year which cite publicly available neuroimaging analysis packages (specifically, FreeSurfer, AFNI, FSL, and SPM).  Although the benefits seem clear for the neuroscience community, analogous efforts within the pulmonary community have yet to be undertaken." }
years <- 2005:2014

numberOfAbstractsPerYear <- rep( 0, length( years ) )
for( i in 1:length( years ) )
  {
  cat( "Doing year", years[i], "\n" )
  query = "afni OR fsl OR freesurfer OR (statistical AND parametric AND mapping)"
  res <- EUtilsSummary( query, db = "pubmed", retmax = 5000, mindate = as.character( years[i] ), maxdate = as.character( years[i] ) )
  summary( res )
  fetch <- EUtilsGet( res )
  abstracts <- AbstractText( fetch )
  numberOfAbstractsPerYear[i] <- length( abstracts )
  }

plotDataFrame <- data.frame( Year = as.factor( years ), NumberOfAbstracts = numberOfAbstractsPerYear )
ggplot( data = plotDataFrame, aes( x = Year, y = NumberOfAbstracts, fill = NumberOfAbstracts ) ) +
          geom_bar( stat = "identity" ) +
          scale_fill_gradient( low = "#01256e", high = "#6d0e0e" ) +
          ylab( "Number of articles" ) +
          xlab( "Publication year" ) +
          theme( legend.position = "none" )
```

Medical image analysis libraries (e.g., the NIH-sponsored Insight ToolKit) provide extensive algorithmic
capabilities for a range of generic image processing tasks.  However,
tailored software packages for certain application domains (e.g., lung image analysis) are not
available despite the vast number of algorithms that have been proposed in the literature.
Note that the goals of this proposal would
significantly support the National Library of Medicine’s own open-source directives in that
all software would be developed using the established Insight ToolKit’s coding and testing
standards with the eventual idea that much (if not all) of the actual code would be contributed
for inclusion in future versions of the Insight ToolKit as we have done in the past.
It should also be noted that open-source software, in general, has documented benefits
within the targeted communities for which it is developed and supported.  In addition to
the increase in research output illustrated earlier, open-source permits students and
researchers to learn specific computational techniques in a social environment [@Yunwen:2003aa].
This, in turn, provides motivation for user-based support including potential contributions
such as bug fixes and feature additions.  Additional analyses have shown the tremendous
cost savings that open-source software yields [@Rothwell:2008aa].

### 3(a.2) ANTs and the neuroimaging community

Deficiency of publicly available tools within the neuroscience community has been one of
the primary motivations for the
inception and continued development of our Advanced Normalization Tools (ANTs).  ANTs takes advantage of
the mature Insight ToolKit in providing an optimal software framework for building scripts
and programs specifically for neuroimaging.  For example, the following core neuroimage
processing algorithms have been made available through our ANTs toolkit (complete with
online self-contained examples with developer-tuned parameters) and have been used extensively by our group and
others:

* brain normalization [@Avants:2011ab;@Avants:2014aa] (https://github.com/stnava/BasicBrainMapping),
* brain template generation [@Avants:2010aa] (https://github.com/ntustison/TemplateBuildingExample),
* skull-stripping or brain extraction [@Avants:2010ab;@Tustison:2014ab] (https://github.com/ntustison/antsBrainExtractionExample),
* prior-based brain tissue segmentation [@Avants:2011ab] (https://github.com/ntustison/antsAtroposN4Example),
* cortical  thickness estimation [@Das:2009aa;@Tustison:2014ab] (https://github.com/ntustison/antsCorticalThicknessExample),
* brain tumor segmentation [@Tustison:2014aa] (https://github.com/ntustison/ANTsAndArboles), and
* cortical labeling [@Wang:2012aa;@Wang:2013aa] (https://github.com/ntustison/MalfLabelingExample).

In addition to public availability, some of these algorithms have been showcased in
international competitions and have performed extremely well [@Murphy:2011aa;@Wang:2012aa;@Menze:2014aa].

### 3(a.3) The significance of ANTs for the pulmonary imaging community

Analogously, several algorithmic categories exist for lung image analysis which, as we have
stated previously, do not exist in any comprehensive, publicly available package.  An
extensive survey concentrating on the years 1999–2004 is given in [@Sluimer:2006aa] which covers computer
aided diagnosis of lung disease and lung cancer in CT (i.e., detection and tracking of
pulmonary nodules) and provides an overview of the many relevant segmentation methods for
pulmonary structures. Although many algorithms existed at the time, continued technical
development has only increased the number of available algorithms.  The following is a small
sampling of more recently reported techniques for CT analysis:

* whole lung differentiation from the chest wall (e.g., [@De-Nunzio:2011aa;@Prasad:2008aa;@Wang:2009aa;@Rikxoort:2009aa])
* bronchial structure extraction (e.g.,[@Zheng:2007aa;@Nakamura:2008aa]; the many submissions to the recent Extraction of Airways from CT (ExACT) challenge of the 2nd International Workshop on Pulmonary Image Analysis [@Lo:2009aa]),
* vasculature segmentation (e.g., [@Agam:2005aa;@Korfiatis:2011aa]),
* lobe and/or fissure detection (e.g., [@Qi:2014aa;@Doel:2015aa]), and
* feature extraction and classification (e.g., [@Uppaluri:1999aa;@Rosas:2011aa;@DeBoer:2014aa]).

Since this list is restricted to CT image analysis, inclusion of additional techniques
specific to other modalities will have additional benefit.  For example, ventilation-based
segmentation for analysis of ventilation lung imaging (e.g., [@Tustison:2011aa] which was
implemented within the ANTs framework) will also have significant impact in a comprehensive
lung image analysis suite.  Since most of the tools that have been developed within the
ANTs framework have generic applicability, crucial to the development of our proposed toolset
will be domain-specific experience.  For example, although ANTs performance in brain
registration has been independently evaluated and found to be of relatively high quality
[Klein2009], tailoring our registration tool in the EMPIRE10 challenge (Evaluation of Methods
for Pulmonary Image REgistration 2010) required significant empirically-based tuning.  In
addition, new innovations in diffeomorphic registration technology has led to a Symmetric
Normalization B-spline variant which has demonstrated accurate normalizations [@Tustison:2013ac],
and transformations which are particularly well-suited for pulmonary data [@Tustison:2015aa].

<!--
Our previous experience in providing well-vetted tools for neuroimage analysis and our extensive
pulmonary research background makes our group well-suited for accomplishing the aims of this proposal and much
of it has and will use ITK and ANTs as a software foundation.
-->

## __3(b) Innovation__

### 3(b.1) Open source pulmonary algorithmic innovation
Given the lack of open-source solutions for pulmonary image analysis,
the proposal goals would produce an innovative platform for performing such research.
Similar to the brain-specific algorithms provided in our ANTs toolkit, our novel
and useful proposal would include several essential algorithms for analyzing lung
images from different modalities including CT, 3He, and proton MRI.
Many algorithms have been proposed in various technical venues but that which we propose
would provide well-vetted and easy-to-use implementations of specific robust methodologies
for pulmonary medical image analysis, many of which have been developed by our group.
To facilitate the usage of these algorithms, we will provide several self-contained
online examples (complete with data).

### 3(b.2) Publicly available multi-site data as a reproducible and didactic component

An additional innovative component we are proposing is the inclusion of complete study
data and detailed instructions for generating reproducible, multimodality pulmonary studies
using the proposed package with
input data from several of our external collaborators and colleagues.  Specifically, we have
asked several scientists and researchers who are familiar with our work to provide imaging data
of various modalities which we will then process using the proposed toolkit.  These processed
data will then not only be returned to the corresponding providers with detailed instructions
on reproducing these results in their own labs but will also be provided to the public for any
interested researcher to reproduce the results.  Given the different image acquisition sources,
this strategy should also demonstrate the robustness of our tools.

Included in these analyses will be analyses of our own data.  Any clinical findings
of interest will be published in traditional venues (e.g., Chest).  In addition, we will
provide all image
data and the quantitative analysis scripts as a companion release to accompany the paper
(e.g., see previous similar offerings from our group [@Tustison:2013ac;@Tustison:2014ab]).
 Such a comprehensive clinical
investigation using these tools will not only provide insight into the specifics of certain
pulmonary pathologies
but will also provide a reproducible mechanism for using the tools created with this proposal.

## __3(c) Research design__

### 3(c.1) Preliminary data

### 3(c.2) Specific Aim 1:   To develop a set of open-source software tools for CT, proton, and 3He pulmonary computational analysis.

Although the proposed software library would be extendable based on new methodological
developments and continued analysis experience, the core development will include several fundamental
tools:

__B-spline-based Symmetric Normalization.__  A thorough comparison with the
well-known ANTs SyN algorithm [@Avants:2008aa] was performed with a B-spline variant [@Tustison:2013ac].
This evaluation utilized multiple publicly available, annotated brain data sets and
demonstrated statistically significant improvement in label overlap measures.  As part of
that study, we produced the scripts ``antsRegistrationSyN.sh`` and
``antsRegistrationSyNQuick.sh`` which provide a simple interface to our normalization tools
for brain-specific normalization based on our extensive experience.

Similarly, we used the EMPIRE10 challenge framework to provide an additional comparison in
the context of pulmonary CT image registration [@Tustison:2012aa].  Registration accuracy
is based on a combination of factors including lung boundary and fissure overlap, landmark
correspondence, and topology considerations in the displacement field.  In this domain, the
B-spline variant showed a separate performance gain and has since become
the preferred transformation model for small deformation image registration problems
(an additional domain is cardiac MRI where it recently won the best paper
award [@Tustison:2015ab]).  As part of the development, we will provide simple script-based
interfaces for lung-specific normalization tasks.

__Multi-feature CT and multi-modal MRI template generation.__  Given the variability in lung shape across
populations and the lack of publicly available lung atlases, generating population- or
subject-specific templates significantly enhances study potential.  Although the template
construction algorithm described in [@Avants:2010aa] was applied to T1-weighted brain data
(with the extension of multimodal data described in [@Tustison:2014aa]), it is sufficiently
generic  such that it is easily applied to pulmonary data.

For example, in Fig. 4, we illustrate the major processing components of a recent study
analyzing local changes based on a pulmonary treatment plan [@Tustison:2013ad].  This
study employed several of the tools we are proposing for inclusion in the specified aims.
The firs major component is the construction of a single-subject 3He/proton MRI
template for all five imaging time points.  This step generates the statistical coordinate
system for the voxelwise regression analysis of the normalized intensities to determine
correlation with expected treatment effects.

![Voxelwise regression analysis to determine image-based response to treatment.  First,
a multi-modal, single-subject template is created to bring all time point images to
the same coordinate system.  4-D segmentation is performed on the longitudinal time series
of 3-D image volumes.  Treatment
effects are expected to follow the simplified treatment hypothesis illustrated with the
dashed blue line in the plot on the right.  To explore how the longitudinal change in expected
ventilation follows this treatment hypothesis with image data, we smooth the aligned expected
ventilation maps (to account for potential voxelwise misalignments) and then quantify how the
voxelwise intensities regress with the simplified treatment hypothesis.  This quantification
is visualized using the correlation maps depicted in the template space (top right).  Positive
correlations with the expected treatment effect are rendered in orange whereas negative correlations
are rendered in blue.](Figs/longitudinalStudy.png)

__Atlas-based lung segmentation.__  Identification of anatomical structure in MRI is often a
crucial preprocessing step for quantification of morphological features or ventilation
information from functional images.  Quantitative regional analysis often requires the
identification of lung and lobar anatomy.  Although much algorithmic research for lung
segmentation has been
reported in the CT literature [@Rikxoort:2013aa], co-opting such technologies is complicated by
MRI-specific issues such as RF coil inhomogeneity, presence and resolution of structural detail, and
the absence of a physically-based intensity scaling.

We recently proposed a multi-atlas approach for automatically segmenting the left and right
lungs in proton MRI [@Tustison:2015aa].  Multi-atlas approaches to segmentation have proven highly
successful in neuroimaging [@Wang:2012aa;@Wang:2013aa] and these methods translate readily to
the pulmonary domain.  Wherease many current strategies for lung image segmentation employ
low-level processing techniques based on encodable heuristics, consensus-based strategies,
in contrast, optimize the prior knowledge applied to a specific segmentation problem (cf Figure 3).
The evaluation of our proposed method [@Tustison:2015aa] demonstrated good performance
with Jaccard overlap measures for the left and right lungs being $0.966 \pm 0.018$ and
$0.970 \pm 0.016$, respectively.  One of the benefits of this approach is that can also
be applied effectively to pulmonary CT.

![Sample lung and lobe estimation results in both proton MRI and CT using our
atlas-based strategy.  (Left) Lung segmentation and lobe estimation results for the given
proton MRI.  Although lobe estimation is dependent solely on the warped atlases, we are
able to obtain accurate estimates of lobes which are useful for more regional analysis
and provide a more intuitive and universal subdivision of the lungs than previous partitioning
schemes.  (Right) The utility of this method extends to CT where the integrity of lobar anatomical
markers (such as the lack of fissures illustrated by the red arrows) have been compromised due to
disease.](Figs/lungEstimation.png)

__Atlas-based lobe estimation.__  For regional investigation of certain lung pathologies and
conditions, it is often useful to quantify measurements of interest within more localized
regions, such as the lobes.  However there is little (if any) usable information in proton
MRI for image-based lobar segmentation which has led to alternative geometric subdivisions
which are ad hoc, non-anatomical, and do not adequately address intra- and inter-subject
correspondences.  However, we can take advantage of
inter-subject similarities in lobar geometry to provide a prior-based estimation of
lobar divisions using a consensus labeling approach (cf Figure 2).

To generate the lobe segmentation in a target proton or CT lung image, we first generate the
binary whole lung mask using the whole lung atlas-based estimation.  We
then register the set of CT lung masks which have beeen expertly annotated to the target
binary lung mask using the B-spline
SyN registration approach described earlier [@Tustison:2013ac].
 Subsequently, we warp the set of CT lobe labels to the target image using
the CT mask-to-target mask transformation.  Since we have no intensity information inside
the target lung mask and CT atlas lung masks, we use a simply majority voting strategy to
generate the optimal labeling for the target image.  Following the majority voting, we
remove any labelings outside the lung mask and assign any unlabeled voxels with the label
closest in distance to that voxel.  This methodology is more thoroughly described in
[@Tustison:2015aa] where we showed that lobar overlap measures in proton MRI were on par
with the  state-of-the-art CT methods where fissure information is actually visible
(left upper: $0.882 \pm 0.059$, left lower: $0.868 \pm 0.06$, right upper: $0.852 \pm 0.067$,
right middle: $0.657 \pm 0.130$, right lower: $0.873 \pm 0.063$).

__Ventilation quantification.__
Automated or semiautomated approaches for classifying areas of varying degrees of ventilation
are of potential benefit for pulmonary functional analysis.  In [@Tustison:2011aa], we presented
an automated algorithmic pipeline for ventilation-based partitioning of the lungs in hyperpolarized
3He and 129Xe MRI.  Without ground truth data for evaluation, we used a consensus labeling approach [@Warfield:2004aa]
to simultaneously estimate the true segmentation from given ``raters''
which included the segmentation from our automated approach and the manual tracings of three trained
individuals.  In terms of combined specificity and sensitivity, our automated algorithm
demonstrated superior performance with the added benefit of being reproducible and less
time-consuming.

Since the initial development, we have continued to improve this segmentation pipeline by
incorporating an iterative bias-correction/segmetnation estimation scheme.   An additional
component that improves results is an ANTs-based implementation of the patch-based denoising protocol
described in [@Manjon:2010aa].  Example longitudinal segmentation results are provided
in Figure 4.

![Pulmonary functional segmentation using the algorithmic framework first described in [@Tustison:2011aa]
for hyperpolarized 3He MRI.  These data were taken from a current study looking at the
implications in ventilation pre- and post-albuterol intake including an additional
acquisition at some delay period following the post-albuterol imaging.  The
ventilation-based segmentation is as follows:  red = no ventilation, green = poorly
ventilated, blue = normally ventilated, and yellow = well-ventilated.
Note the improvement in both the qualitative assessment of the ventilation map (top) and the corresponding
segmentation time course (bottom) followed by an approximate return to pre-albuterol
conditions following the delay period.](Figs/prePostAlbuterol.png)

__Quantitative CT indices.__  Imaging biomarkers for characterizing emphysema in CT have
have been well researched, although there are ample opportunities to refine these methods
as well as to introduce more advanced approaches.  Examples of the latter include texture
analysis for identifying the centrilobular and groundglass opacities and fractal and
connectivity approaches to differentiate centrilobular from panlobular emphysema. The
indices for CT image analysis can roughly be divided into those that characterize the
pulmonary parenchyma:
  volumetric tissue (e.g., [@Coxson:1999aa;@Perez:2005aa]),
   distribution of low attenuation areas (LAA) (e.g., [@Coxson:2005aa;@Stolk:2007aa]),
   cooccurrence and run-length matrix features (e.g., [@Uppaluri:1999aa;@Xu:2006aa]),
   attenuation statistics (e.g., [@Gevenois:1996aa;@Hoffman:2006aa]),
   deformation measures (e.g., [@Gee:2003aa;@Sundaram:2005aa]), and
   stochastic fractal dimension features (e.g., [@Uppaluri:1999aa;@Hoffman:2006aa])
and those that characterize the airways (e.g., [@Aykac:2003aa;@Park:1998aa;@Ederle:2003aa]).

The former are important
for subjects with an emphysematous component of disease, whereas the latter are important
for subjects with a bronchitic component of disease. An important premise of this
proposal is that many of these measurements can also be directly applied to discriminative
analysis using 3He MRI for a variety of lung diseases.
These indices can also be studied not
only at any particular single time point, but also for changes with time. The addition of
quantitative morphologic measurements of the airways provides an assessment of the
contribution of airway changes to chronic lung disease.

\input{ct_table.tex}

Table 1 provides an overview of these types of
discriminative measurements that can be used for CT and 3He lung assessment.
We have already
implemented many of these image features and have contributed the result of our work to
the Insight Toolkit (ITK) of the National Institutes of Health (e.g., [@Tustison:2008aa;@Tustison:2009aa]). As an
open-source repository for medical image analysis algorithms, contribution of our work
to the ITK allows researchers full access to the latest image analysis algorithms in
addition to avoiding research redundancy. It is also beneficial in that the entire ITK
community participates in the vetting of the software library.

__Airway and vessel segmentation.__  In describing the quantitative CT lung indices,
it was pointed out that lung airway morphology has been previously utilized as a biomarker
for disease characterization.  Additionally, there are other potential uses motivating
the inclusion of airway segmentation in any pulmonary image analysis toolkit (cf Figure 5).
In an evaluation of 15 airway segmentation algorithms [@Lo:2012aa]
it was shown that no algorithm was capable of ``extracting more than 77% of the reference.''
Our plan is to initially provide an implementation of the algorithm developed by our group [@Song:2010aa].
Instead of mixing airway segmentation and leakage detection at every iteration, this work divides
this problem into a hypothesis generation of thin airway paths and a post processing
procedure of removing leakage path candidates. For the purpose of generating as many
hypotheses as possible, a novel speed function for thin airways is used. To exclude
leakage regions, a novel cost function defined on the whole path candidate is used.
Such a scheme is more flexible when evaluating the whole path and can be viewed as
complementary to current region growing methods.

![Potential clinical use case for identifying the feeding airway branch path to the
ventilation defect.  The functional ventilation image is normalized to the corresponding
CT image.  The airways are segmented in the individual subject space.  After identification
of the ventilation defect of interest, we can automatically determine the bronchiole
pathway from the trachea to the defect.](Figs/airways.png)


__Specific Aim 2.__  To provide multiple sets of multi-modal annotated lung data (CT, proton, and He3) for public use.

__Specific Aim 3.__ Evaluate and disseminate multiple complete studies with input data from
multiple investigators to showcase the utility of the tools and data provided with this proposal.

### Anticipated difficulties
Signal intensity in the lungs is poor in areas of low ventilation. COPD and asthma are
obstructive lung diseases which exhibit focal areas of decreased signal intensity on 3HeMRI
which are thought to correspond to areas of reduced ventilation. These ventilation defects
severely inhibit our ability to detect the lung boundaries for proper segmentation. Also,
most of the COPD and asthmatic patients will have ventilation defects with the moderate
asthmatics having greater than 1 defect per slice also negatively affecting boundary
delineation. Note that there are similar issues for CT images of severe pathologies.
However, given the shape and intensity prior statistics contained by our 3HeMRI and CT
lung templates, it is expected that the templates, in combination with our proposed
segmentation algorithms, will be sufficient to provide a good initialization for subsequent
manual segmentation if they do not yield an adequate segmentation result. The CT data,
which provides excellent contrast between the lung and chest wall, can also be used to
inform the 3HeMRI segmentation.






\clearpage

\newpage

# References

